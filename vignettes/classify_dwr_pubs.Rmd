---
title: "DWR Publication Classification using an LLM"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{DWR Publication Classification using an LLM}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
  
```{r setup, include = FALSE}
knitr::opts_chunk$set(
collapse = TRUE,
fig.align = "center",
out.width = "100%",
comment = "#>"
)

# library(pubclassify)
devtools::load_all()
```

# Introduction

The California Department of Water Resources (DWR) has developed a method for 
classifying peer-reviewed publications to which DWR has contributed authorship 
and/or funded. The classification is performed with a large language model (LLM).


# DWR publication inventory

DWR has built an inventory of peer-reviewed publications from 2020 to the present 
using three techniques:

1. A call to the Crossref API using the general search query term "California 
Department of Water Resources" and a publication date filter of January 1, 2020
or later
2. A call to the Crossref API using DWR's unique funder identifier and a 
publication date filter of January 1, 2020 or later
3. A call to the Crossref API using a list of digital object identifiers (DOIs)
that the California Energy Commission librarian has produced

The these calls produced an inventory that contains `r nrow(dwr_pubs)` unique
peer-reviewed articles. Here are the first eight entries in the inventory:

```{r print-example-citations, echo = FALSE, results = "asis"}
for (i in 1:8) {
  citation <- format_citation(dwr_pubs[i, ], style = "chicago", link_doi = TRUE)
  cat("> ", i, ". ", citation, "\n>\n", sep = "")
}
```

```{r set-up-abstract, echo = FALSE}
# pick the first paper with an abstract
first_abstract_i <- which(!is.na(dwr_pubs$abstract_text))[1]
pub <- dwr_pubs[first_abstract_i, ]

# last‐name + et al.
last_name        <- sub(",.*", "", pub$lead_author_last_name)
author_citation  <- if (pub$author_count == 1) last_name else paste0(last_name, " et al.")

# combine author + pub_year in one go
author_year_citation <- paste0(author_citation, " (", pub$pub_year, ")")

# grab the abstract
abstract_text <- pub$abstract_text
```

The peer-reviewed article inventory includes full abstract text, where available.
For example, here is the abstract associated with the `r author_year_citation`
publication:

```{r print-example-abstract, echo = FALSE, results = "asis"}
cat("> *", abstract_text, "*", sep = "")
```


# Large language model classification

The publication classification is performed using Google's Gemini large language
model. The function `classify_pubs_gemini()` sends each abstract to the model
along with a system prompt that instructs the model on how to perform the
classification.

Here is the system prompt used for classification:

```{r print-system-prompt, echo = FALSE, results = "asis"}
# get the function body
fb <- as.list(body(classify_pubs_gemini))

# find the assignment to system_prompt
sys_assign <- Filter(function(e) {
  is.call(e) &&
    identical(e[[1]], as.symbol("<-")) &&
    identical(e[[2]], as.symbol("system_prompt"))
}, fb)[[1]]

# extract the RHS of that assignment, which is the paste() call
paste_call <- sys_assign[[3]]

# pull out each argument to paste()
prompt_lines <- vapply(
  as.list(paste_call)[-1], # drop the "paste" symbol
  function(arg) eval(arg), # each arg is a literal, so eval() returns the string
  character(1)
)

# use a combination of blockquote and HTML for italic
for(line in prompt_lines) {
  cat("> <em>", line, "</em>\n>\n", sep = "")
}
```

The National Science Foundation (NSF) classification system referenced in the
system prompt is used for the annual NSF Survey of Earned Doctorates (SED). The 
most recent version of the SED taxonomy is [described here](https://ncses.nsf.gov/pubs/ncses23200).

Here is an example of elements in the taxonomy.

```{r show-taxonomy, echo = FALSE}
nsf_sed_taxonomy |>
  dplyr::select(first_level, second_level, third_level) |>
  head(10) |>
  knitr::kable(
    col.names = c(
      "First-level classification", 
      "Second-level classification",
      "Third-level classification"
    )
  ) |>
  kableExtra::kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = TRUE
  ) |>
  kableExtra::row_spec(
    row = 0, 
    bold = TRUE, 
    background = "#E0E0E0",
    extra_css = "vertical-align: middle;"
  )
```


Each abstract was fed to the [Google Gemini 2.0 Flash large language model (LLM)](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-0-flash),
a cost-efficient, non-thinking model with a knowledge cutoff of June 2024. The 
LLM produced a three-level NSF classification for each article.

```{r classify-pubs, include = FALSE}
# this is what would be run to classify publications, but it's time-intensive
# and racks up API charges (which are admittedly inexpensive, but still), so
# the object `dwr_pubs_classified` is loaded as a package data object
if (FALSE) {
  dwr_pubs_classified <- classify_pubs_gemini(dwr_pubs, model = "gemini-2.0-flash")
  
  dwr_pubs_classified <- dplyr::left_join(
    x = dwr_pubs,
    y = dwr_pubs_classified,
    by = "doi"
  )
}
```

```{r display-classified-pubs-table, echo = FALSE}
classified_table <- dwr_pubs_classified |>
  dplyr::filter(!is.na(first_level)) |>
  dplyr::mutate(
    author_format = dplyr::case_when(
      author_count == 1  ~ paste0(lead_author_last_name, ", ", lead_author_first_name),
      author_count >  1  ~ paste0(lead_author_last_name, ", ", lead_author_first_name, " et al.")
    ),
    article = paste0(
      author_format,
      " (", pub_year, "). ",
      title
    )
  ) |>
  dplyr::select(article, first_level, second_level, third_level) |>
  head(10)

classified_table |>
  knitr::kable(
    col.names = c(
      "Article",
      "First-level classification", 
      "Second-level classification",
      "Third-level classification"
    )
  ) |>
  kableExtra::kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = TRUE
  ) |>
  kableExtra::column_spec(column = 1, width = "40%") |>
  kableExtra::column_spec(column = 2:4, width = "20%") |>
  kableExtra::row_spec(
    row = 0, 
    bold = TRUE, 
    background = "#E0E0E0",
    extra_css = "vertical-align: middle;"
  )
```

## Classification visualizations

```{r count-first-level, echo = FALSE}
# grab counts of first-level observations
first_level_counts <- dwr_pubs_classified |>
  dplyr::filter(!is.na(first_level)) |>
  dplyr::count(first_level, sort = TRUE) |>
  dplyr::mutate(first_level = forcats::fct_reorder(first_level, n)) |>
  dplyr::arrange(dplyr::desc(n))

minimal_papers <- first_level_counts |>
  dplyr::filter(n <= 3) |>
  dplyr::pull(first_level)

# collapse with "; " normally but "; and " before the last item
minimal_papers_string <- if (length(minimal_papers) <= 1) {
  minimal_papers
} else {
  glue::glue_collapse(minimal_papers, sep = "; ", last = "; and ")
}
```

Since 2020, DWR has published the most papers in the first-level classification
of `r first_level_counts$first_level[1]` (`r first_level_counts$n[1]` papers),
followed by `r first_level_counts$first_level[2]` (`r first_level_counts$n[2]`
papers). Only a handful of papers have been published in `r minimal_papers_string`.

```{r visualize-first-level, echo = FALSE, fig.width = 10, fig.height = 6}
# pick an interval for the y axis (which becomes x axis with coord_flip())
y_interval <- 20
y_max_n    <- max(first_level_counts$n)
y_upper    <- ceiling((y_max_n + 0.1 * y_max_n) / y_interval) * y_interval


# make a bar plot
ggplot2::ggplot(first_level_counts, ggplot2::aes(x = first_level, y = n)) +
  ggplot2::geom_bar(stat = "identity", fill = "black", alpha = 0.8, width = 0.5) +
  ggplot2::geom_text(ggplot2::aes(label = n), hjust = -0.2) +
  ggplot2::scale_x_discrete(labels = function(x) stringr::str_wrap(x, width = 30)) +
  ggplot2::scale_y_continuous(
    expand = ggplot2::expansion(add = c(0, 10)),
    breaks = seq(from = 0, to = y_upper, by = y_interval)
  ) +
  ggplot2::coord_flip() +
  ggplot2::labs(
    title = "Distribution of publications by NSF first-level classification",
    x = NULL,
    y = "number of publications"
  ) +
  ggplot2::theme_minimal() +
  ggplot2::theme(
    plot.title = ggplot2::element_text(face = "bold", size = 16),
    axis.title.x = ggplot2::element_text(
      face = "bold",
      size = 14,
      margin = ggplot2::margin(t = 20)
    ),
    axis.text.x = ggplot2::element_text(size = 12),
    axis.text.y = ggplot2::element_text(size = 12)
  )
```

```{r count-second-level, echo = FALSE}
# count first and second levels
first_second_level_counts <- dwr_pubs_classified |>
  dplyr::filter(!is.na(first_level)) |>
  dplyr::count(first_level, second_level) |>
  dplyr::arrange(desc(n))

second_level_top3 <- first_second_level_counts |>
  dplyr::arrange(dplyr::desc(n)) |>
  head(3)

second_level_labels <- second_level_top3 |>
  dplyr::transmute(label = glue::glue("{second_level} ({n} papers)")) |>
  dplyr::pull(label)

second_level_string <- if (length(second_level_labels) <= 1) {
  second_level_labels
} else {
  glue::glue_collapse(
    second_level_labels,
    sep  = ", ",
    last = ", and "
  )
}
```

Drilling down one level further in the classification, we can see that many papers
have been published that address `r second_level_string`.

```{r visualize-hierarchy, echo = FALSE, fig.width = 10, fig.height = 8}
# make a custom palette for first‐level groups
n_categories   <- length(unique(first_second_level_counts$first_level))
custom_colors <- grDevices::colorRampPalette(
  RColorBrewer::brewer.pal(12, "Paired")
)(n_categories)

# plot a hierarchy map
ggplot2::ggplot(
  first_second_level_counts,
  ggplot2::aes(
    area     = n,
    fill     = first_level,
    subgroup = first_level,
    label    = stringr::str_wrap(second_level, width = 10)
  )
) +
  treemapify::geom_treemap() +
  treemapify::geom_treemap_subgroup_border(color = "white", size = 1) +
  treemapify::geom_treemap_text(
    color  = "white",
    place  = "centre",
    size   = 2,
    grow   = TRUE,
    reflow = TRUE
  ) +
  ggplot2::scale_fill_manual(
    values = custom_colors,
    name   = "NSF classification",
    labels = function(x) stringr::str_wrap(x, width = 30)
  ) +
  ggplot2::labs(
    title    = "Hierarchical view of NSF first- and second-level classifications",
    subtitle = "Area represents number of publications"
  ) +
  ggplot2::theme_minimal() +
  ggplot2::theme(
    plot.title       = ggplot2::element_text(face = "bold", size = 16),
    plot.subtitle    = ggplot2::element_text(face = "italic", size = 12),
    legend.position  = "right",
    legend.title     = ggplot2::element_text(face = "bold", size = 14),
    legend.text      = ggplot2::element_text(size = 12)
  )
```

```{r time-series-string-prep, include = FALSE}
# calculate overall annual counts
annual_counts <- dplyr::count(dwr_pubs_classified, pub_year)
years         <- sort(annual_counts$pub_year)
start_year    <- 2020
end_year      <- max(years)
start_count   <- annual_counts$n[annual_counts$pub_year == start_year]
peak_idx      <- which.max(annual_counts$n)
peak_year     <- annual_counts$pub_year[peak_idx]
peak_count    <- annual_counts$n[peak_idx]
end_count     <- annual_counts$n[annual_counts$pub_year == end_year]

# identify top two fields by total publications
top_two <- dplyr::count(dwr_pubs_classified, first_level) |>
  dplyr::filter(!is.na(first_level)) |>
  dplyr::arrange(dplyr::desc(n)) |>
  head(2) |>
  dplyr::pull(first_level)

# pick a few smaller fields to mention
small_fields <- c("agronomy", "genetics", "political science")
small_max <- dplyr::count(dwr_pubs_classified, pub_year, first_level) |>
  dplyr::filter(first_level %in% small_fields) |>
  dplyr::pull(n) |>
  max(na.rm = TRUE)
```

Total DWR publications rose from `r start_count` in `r start_year` to a peak of
`r peak_count` in `r peak_year`. The two leading fields—`r top_two[1]` and
`r top_two[2]`—have variable counts of publications per year, reflecting ebbs
and flows in scientific work, likely due to the impacts of COVID-19 in this
analysis window. Smaller topics such as `r glue::glue_collapse(small_fields, sep = ", ", last = ", and ")`, with no more than `r small_max` papers in any year, remain relatively flat over
the period.

```{r visualize-time-trend, echo = FALSE, fig.width = 10, fig.height = 8}
# extract and count pub_year + first_level
time_trend <- dplyr::count(
  dplyr::filter(
    dwr_pubs_classified,
    !is.na(first_level),
    !is.na(pub_year)
  ),
  pub_year,
  first_level
)

# build complete grid of years × classifications
all_years           <- sort(unique(time_trend$pub_year))
all_classifications <- unique(time_trend$first_level)

complete_grid <- expand.grid(
  pub_year = all_years,
  first_level = all_classifications,
  stringsAsFactors = FALSE
)

time_trend <- dplyr::left_join(
  complete_grid,
  time_trend,
  by = c("pub_year", "first_level")
) |>
  dplyr::mutate(n = tidyr::replace_na(n, 0))

# plot the time trend
ggplot2::ggplot(
  time_trend,
  ggplot2::aes(
    x     = pub_year,
    y     = n,
    color = first_level,
    group = first_level
  )
) +
  ggplot2::geom_line(linewidth = 1.5, alpha = 0.9) +
  ggplot2::geom_point(size = 3) +
  ggplot2::scale_color_manual(
    values = custom_colors,
    name   = "NSF classification",
    labels = function(x) stringr::str_wrap(x, width = 30)
  ) +
  ggplot2::labs(
    title    = "Trend in NSF classifications over time",
    subtitle = "Number of publications by classification and year",
    x        = "Publication year",
    y        = "Number of publications"
  ) +
  ggplot2::scale_x_discrete(
    breaks = seq(
      from = min(all_years),
      to   = max(all_years),
      by   = 1
    )
  ) +
  ggplot2::scale_y_continuous(
    breaks = seq(
      from = 0,
      to   = max(time_trend$n) + 5,
      by   = 5
    ),
    expand = ggplot2::expansion(add = c(1, 5))
  ) +
  ggplot2::theme_minimal() +
  ggplot2::theme(
    plot.title       = ggplot2::element_text(face = "bold", size = 16),
    plot.subtitle    = ggplot2::element_text(face = "italic", size = 12),
    legend.position  = "right",
    legend.title     = ggplot2::element_text(face = "bold", size = 14),
    legend.text      = ggplot2::element_text(size = 12),
    panel.grid.minor = ggplot2::element_blank(),
    axis.title.x     = ggplot2::element_text(
      face   = "bold",
      size   = 14,
      margin = ggplot2::margin(t = 20)
    ),
    axis.title.y     = ggplot2::element_text(
      face   = "bold",
      size   = 14,
      margin = ggplot2::margin(r = 20)
    ),
    axis.text.x      = ggplot2::element_text(size = 12),
    axis.text.y      = ggplot2::element_text(size = 12)
  )
```
